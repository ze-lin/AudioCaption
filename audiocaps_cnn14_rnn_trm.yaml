outputpath: experiments/audiocaps/pre_val
remark: panns_cnn14_rnn_attnrnn_label_average_seq_concat_word

data:
    train:
        raw_feat_csv: data/audiocaps/train/lms.csv
        fc_feat_csv: data/audiocaps/train/panns_fc.csv
        attn_feat_csv: data/audiocaps/train/panns_attn.csv
        caption_file: data/audiocaps/train/text.json
    val:
        raw_feat_csv: data/audiocaps/val/lms.csv
        fc_feat_csv: data/audiocaps/val/panns_fc.csv
        attn_feat_csv: data/audiocaps/val/panns_attn.csv
        caption_file: data/audiocaps/val/text.json
    vocab_file: data/audiocaps/train/vocab.pkl
zh: False
dataloader_args:
    batch_size: 64
    num_workers: 4
# sampler_args:
    # max_cap_num: 1
augments: [timemask, freqmask, randomcrop]
distributed: False
use_label: True


encoder: RnnEncoder
encoder_args: 
    bidirectional: True
    hidden_size: 256
    num_layers: 3
    dropout: 0.5
decoder: TransformerDecoder
decoder_args:
    emb_dim: 256
    fc_emb_dim: 512
    attn_emb_dim: 512
    n_layers: 2
    dropout: 0.2
model: TransformerModel
model_args: {}

improvecriterion: score # Can be acc | loss | score

optimizer: Adam
optimizer_args:
    lr: !!float 5e-4
    weight_decay: !!float 1e-6
max_grad_norm: 1.0
epochs: 25
scheduler: ExponentialDecayScheduler
scheduler_args:
    # warmup_iters: 4000
    final_lrs: !!float 5e-7

ss: True
ss_args:
    ss_mode: linear
    ss_ratio: 1.0
    final_ss_ratio: 0.7

loss: LabelSmoothingLoss
loss_args:
    smoothing: 0.1

swa: True
swa_start: 21
